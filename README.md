RAG Admin Pipeline
ğŸš€ Retrieval-Augmented Generation (RAG) Administration Platform
A production-ready, enterprise-grade Retrieval-Augmented Generation (RAG) pipeline built with FastAPI, designed for document ingestion, semantic search, and AI-powered question answering.

ğŸ“‹ Table of Contents
Features

Architecture

Quick Start

Installation

Configuration

Usage

API Documentation

Project Structure

Technologies

Contributing

License

âœ¨ Features
Core Capabilities
âœ… Document Ingestion

Support for PDF, DOCX, TXT, Markdown files

Automatic text extraction and parsing

OCR support for scanned documents

âœ… Intelligent Chunking

Semantic-aware text splitting

Configurable chunk size and overlap

Sentence and paragraph preservation

âœ… Embedding Generation

BGE (BAAI General Embeddings) models

GPU acceleration support

Batch processing

Embedding caching

âœ… Vector Storage & Search

FAISS (Facebook AI Similarity Search)

Million-scale vector indexing

Sub-millisecond similarity search

Metadata filtering

âœ… Retrieval & Ranking

Top-K similar document retrieval

BM25 + vector hybrid search

Relevance scoring

âœ… LLM Integration

OpenAI GPT-4, GPT-3.5

Anthropic Claude

Custom LLM support

âœ… Admin Dashboard (API)

Document management

Knowledge base administration

Query testing

Analytics & monitoring

ğŸ—ï¸ Architecture
System Design
text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLIENT INTERFACE                        â”‚
â”‚              (Web UI / API Clients)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API GATEWAY (FastAPI)                     â”‚
â”‚         (Authentication, Routing, Rate Limiting)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            â”‚           â”‚           â”‚             â”‚
â–¼            â–¼           â–¼           â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document â”‚ â”‚Chunkingâ”‚ â”‚Embeddingâ”‚ â”‚Vector â”‚  â”‚ Retrievalâ”‚
â”‚Processingâ”‚ â”‚ Module â”‚ â”‚ Module  â”‚ â”‚ Store â”‚  â”‚ Module   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚          â”‚         â”‚          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Data Layer      â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ PostgreSQL (Meta)  â”‚
              â”‚ Redis (Cache)      â”‚
              â”‚ FAISS (Vectors)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   LLM Services     â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ OpenAI             â”‚
              â”‚ Anthropic          â”‚
              â”‚ Custom Models      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Data Flow
text
Document Upload
    â†“
Document Parsing
    â”œâ”€ PDF extraction
    â”œâ”€ DOCX extraction
    â”œâ”€ TXT reading
    â””â”€ Metadata extraction
    â†“
Text Cleaning & Normalization
    â”œâ”€ Remove special characters
    â”œâ”€ Normalize whitespace
    â””â”€ Handle encoding
    â†“
Semantic Chunking
    â”œâ”€ Split by paragraphs
    â”œâ”€ Respect sentence boundaries
    â””â”€ Apply overlap
    â†“
Embedding Generation
    â”œâ”€ BGE model inference
    â”œâ”€ Batch processing
    â””â”€ Normalize vectors
    â†“
Vector Indexing
    â”œâ”€ Store in FAISS
    â”œâ”€ Index metadata
    â””â”€ Cache embeddings
    â†“
Knowledge Base Ready
    â””â”€ Ready for queries
ğŸš€ Quick Start
Prerequisites
Python 3.9+

PostgreSQL 12+

Redis 6+

4GB RAM minimum (8GB+ recommended)

GPU optional (NVIDIA CUDA for acceleration)

1. Clone Repository
bash
git clone https://github.com/yourusername/rag-admin-pipeline.git
cd rag-admin-pipeline
2. Create Virtual Environment
bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
3. Install Dependencies
bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
4. Configure Environment
bash
cp .env.example .env
# Edit .env with your actual values
nano .env
5. Initialize Database
bash
alembic upgrade head
6. Start Application
bash
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
7. Access Application
text
API Documentation: http://localhost:8000/docs
Alternative Docs:  http://localhost:8000/redoc
Health Check:      http://localhost:8000/health
ğŸ“¦ Installation
Detailed Installation Steps
1. System Dependencies (Ubuntu/Debian)
bash
sudo apt-get update
sudo apt-get install -y python3.9 python3.9-venv postgresql redis-server
2. Python Environment
bash
python3.9 -m venv venv
source venv/bin/activate
pip install --upgrade pip setuptools wheel
3. Project Dependencies
bash
# Core dependencies
pip install -r requirements.txt

# Optional: GPU support for FAISS
pip install faiss-gpu

# Optional: PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
4. Database Setup
bash
# Create PostgreSQL database
createdb rag_admin_db

# Run migrations
alembic upgrade head

# Optional: Load sample data
python scripts/load_samples.py
5. Redis Setup
bash
# Start Redis server
redis-server

# Test connection
redis-cli ping  # Should output: PONG
âš™ï¸ Configuration
Environment Variables (.env)
text
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/rag_admin_db

# Redis
REDIS_URL=redis://localhost:6379/0

# Security
SECRET_KEY=your-super-secret-key-min-32-chars
ALGORITHM=HS256

# API Keys
OPENAI_API_KEY=sk-your-key-here

# Vector DB
VECTORDB_DIMENSION=384
VECTORDB_INDEX_TYPE=flat

# Embeddings
EMBEDDER_MODEL_NAME=BAAI/bge-small-en-v1.5
EMBEDDER_DEVICE=cuda  # or cpu

# Application
DEBUG=false
ENV=production
LOG_LEVEL=INFO
Configuration Files
text
config/
â”œâ”€â”€ settings.yaml          # Application settings
â”œâ”€â”€ models.yaml           # Model configurations
â””â”€â”€ logging.yaml          # Logging configuration
ğŸ’» Usage
API Examples
1. Upload Document
bash
curl -X POST "http://localhost:8000/api/v1/documents/upload" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@document.pdf"
2. Create Knowledge Base
bash
curl -X POST "http://localhost:8000/api/v1/knowledge-bases" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "My Knowledge Base",
    "description": "Company documentation"
  }'
3. Query Knowledge Base
bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How do I use this feature?",
    "knowledge_base_id": "kb_123",
    "top_k": 5
  }'
Python Client
python
from rag_client import RAGClient

# Initialize client
client = RAGClient(
    api_url="http://localhost:8000",
    api_key="your-api-key"
)

# Upload document
document_id = client.upload_document(
    file_path="document.pdf",
    kb_id="kb_123"
)

# Query
results = client.query(
    query="What is this about?",
    kb_id="kb_123",
    top_k=5
)

for result in results:
    print(f"Score: {result.score}")
    print(f"Content: {result.content}")
ğŸ“š API Documentation
Interactive Documentation
Swagger UI: http://localhost:8000/docs

ReDoc: http://localhost:8000/redoc

Key Endpoints
Method	Endpoint	Description
POST	/api/v1/documents/upload	Upload document
GET	/api/v1/documents/{id}	Get document details
DELETE	/api/v1/documents/{id}	Delete document
POST	/api/v1/query	Query knowledge base
GET	/api/v1/knowledge-bases	List knowledge bases
POST	/api/v1/knowledge-bases	Create knowledge base
ğŸ“ Project Structure
text
rag-admin-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config/                 # Configuration
â”‚   â”œâ”€â”€ models/                 # Database models
â”‚   â”œâ”€â”€ schemas/                # Pydantic schemas
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth/              # Authentication
â”‚   â”‚   â””â”€â”€ middleware/        # Request middleware
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ chunking/          # Document chunking
â”‚   â”‚   â”œâ”€â”€ embeddings/        # Embedding generation
â”‚   â”‚   â”œâ”€â”€ ingestion/         # Document ingestion
â”‚   â”‚   â”œâ”€â”€ vectordb/          # Vector database
â”‚   â”‚   â””â”€â”€ preprocessors/     # Text preprocessing
â”‚   â”œâ”€â”€ db/                    # Database setup
â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml          # Settings
â”‚   â”œâ”€â”€ logging.yaml           # Logging config
â”‚   â””â”€â”€ models.yaml            # Model configs
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ load_samples.py        # Load sample data
â”‚   â”œâ”€â”€ create_indexes.py      # Create database indexes
â”‚   â””â”€â”€ migrate.py             # Database migration
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ DEVELOPMENT.md
â”‚
â”œâ”€â”€ .env                        # Environment variables (NEVER commit)
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ docker-compose.yml         # Docker setup
â”œâ”€â”€ Dockerfile                 # Docker image
â””â”€â”€ alembic.ini                # Database migration config
ğŸ› ï¸ Technologies
Backend
FastAPI: Modern async web framework

SQLAlchemy: ORM and database toolkit

Pydantic: Data validation

AI/ML
FAISS: Vector similarity search

Sentence Transformers: BGE embeddings

LangChain: LLM orchestration

OpenAI/Anthropic: LLM APIs

Database
PostgreSQL: Primary data store

Redis: Caching and sessions

FAISS: Vector indexes

DevOps
Docker: Containerization

Docker Compose: Local development

Alembic: Database migrations

ğŸ§ª Testing
Run Tests
bash
# All tests
pytest

# With coverage
pytest --cov=src

# Specific test file
pytest tests/unit/test_chunking.py

# Verbose output
pytest -v
Test Coverage
bash
pytest --cov=src --cov-report=html
open htmlcov/index.html
ğŸ“– Development
Install Development Dependencies
bash
pip install -r requirements.txt
pip install pytest black flake8 mypy
Code Quality
bash
# Format code
black src tests

# Check linting
flake8 src tests

# Type checking
mypy src
Local Development
bash
# Start with auto-reload
uvicorn src.main:app --reload

# With debug logging
DEBUG=true LOG_LEVEL=DEBUG uvicorn src.main:app --reload
ğŸš¢ Deployment
Docker Deployment
bash
# Build image
docker build -t rag-pipeline:latest .

# Run container
docker run -p 8000:8000 --env-file .env rag-pipeline:latest
Docker Compose (All Services)
bash
docker-compose up -d
Production Deployment
See DEPLOYMENT.md

ğŸ“Š Monitoring & Logging
Prometheus Metrics
text
http://localhost:8001/metrics
Logs Location
bash
tail -f logs/app.log
Health Check
bash
curl http://localhost:8000/health
ğŸ¤ Contributing
Development Workflow
Create feature branch: git checkout -b feature/my-feature

Make changes and commit: git commit -am "Add feature"

Push to branch: git push origin feature/my-feature

Create Pull Request

Code Standards
Follow PEP 8

100% test coverage for new features

Update documentation

Run code quality checks

ğŸ“ License
This project is licensed under the MIT License - see LICENSE file for details.

ğŸ†˜ Troubleshooting
Common Issues
Issue: Database connection failed

bash
# Check PostgreSQL is running
pg_isready -h localhost -p 5432

# Check connection string in .env
echo $DATABASE_URL
Issue: Redis connection failed

bash
# Check Redis is running
redis-cli ping

# Update REDIS_URL in .env
Issue: FAISS installation fails

bash
# Try CPU version
pip install faiss-cpu

# Or specific GPU version
pip install faiss-gpu

Getting Help

ğŸ“ Contact & Support
