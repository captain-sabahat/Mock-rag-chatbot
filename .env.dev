============================================================================
RAG PIPELINE - Complete Configuration (.env.dev)
============================================================================
Development environment with free, local-only tools
Pipeline: Ingest → Preprocess → Chunk → Embed → Upsert to VectorDB
============================================================================
ENVIRONMENT SELECTION
============================================================================
ENV=dev
LOG_LEVEL=INFO
DEBUG_MODE=true

============================================================================
INGEST NODE - Document Ingestion Settings
============================================================================
Responsibility: Load raw documents from disk/sources
INGEST_BATCH_SIZE=10
INGEST_MAX_WORKERS=4
SOURCE_DOC_PATHS=./mock_data/raw_docs/
INGEST_OUTPUT_PATH=./mock_data/processed/
INGEST_SUPPORTED_FORMATS=pdf,txt,docx,json
INGEST_MAX_FILE_SIZE_MB=100
INGEST_TIMEOUT_SECONDS=300

============================================================================
PREPROCESS NODE - Document Preprocessing Settings
============================================================================
Responsibility: Clean, normalize, extract text from documents
PREPROCESS_CLEAN_HTML=true
PREPROCESS_REMOVE_STOPWORDS=true
PREPROCESS_LANGUAGE=en
TEXT_CLEANER=spacy
PREPROCESS_REMOVE_URLS=true
PREPROCESS_REMOVE_EMAILS=true
PREPROCESS_NORMALIZE_WHITESPACE=true
PREPROCESS_LOWERCASE=false
PREPROCESS_REMOVE_SPECIAL_CHARS=false
PREPROCESS_MIN_TEXT_LENGTH=50

============================================================================
CHUNKING NODE - Text Chunking Settings
============================================================================
Responsibility: Split preprocessed text into semantic chunks
CHUNKING_STRATEGY=semantic
CHUNK_SIZE=512
CHUNK_OVERLAP=50
CHUNK_MIN_LENGTH=100
CHUNK_MAX_LENGTH=800
CHUNK_EMBEDDING_CACHE=true
CHUNK_SEPARATOR=\n\n
CHUNK_PRESERVE_PARAGRAPH=true
CHUNK_TIMEOUT_SECONDS=60

============================================================================
EMBEDDINGS NODE - Vector Embedding Settings
============================================================================
Responsibility: Convert text chunks into vector embeddings
FREE OPTION: HuggingFace sentence-transformers (no API key required)
EMBEDDINGS_PROVIDER=huggingface
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_MODEL_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32
EMBEDDING_NORMALIZE=true
EMBEDDING_CACHE_FOLDER=./models/embeddings
EMBEDDING_DIMENSION=384
HF_TOKEN=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

Disabled: OpenAI (Paid - requires API key)
EMBEDDINGS_OPENAI_API_KEY=
EMBEDDINGS_OPENAI_MODEL=text-embedding-3-small
EMBEDDINGS_OPENAI_DIMENSIONS=1536

Disabled: Cohere (Paid - requires API key)
EMBEDDINGS_COHERE_API_KEY=
EMBEDDINGS_COHERE_MODEL=embed-english-v3.0
EMBEDDINGS_COHERE_DIMENSIONS=1024

============================================================================
VECTOR DATABASE NODE - Vector Storage Settings
============================================================================
Responsibility: Store and retrieve vector embeddings
FREE OPTION: FAISS (Local, in-memory, no setup required)
VECTORDB_PROVIDER=faiss
VECTOR_DB_TYPE=faiss
FAISS_INDEX_PATH=./mock_data/faiss_index
FAISS_INDEX_TYPE=IndexFlatL2
FAISS_INDEX_DIM=384
FAISS_METRIC_TYPE=L2
FAISS_NLIST=100
FAISS_NPROBE=10
FAISS_SAVE_INDEX=true
FAISS_NORMALIZE=true

Disabled: Qdrant (Requires server)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=documents

Disabled: Pinecone (Paid cloud service)
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=rag-documents

============================================================================
UPSERT NODE - Vector DB Insertion Settings
============================================================================
Responsibility: Insert/update embeddings into vector database
UPSERT_BATCH_SIZE=100
UPSERT_MAX_RETRIES=3
UPSERT_TIMEOUT_SECONDS=60
UPSERT_DEDUP_ENABLED=true
UPSERT_DEDUP_METHOD=hash
UPSERT_OVERWRITE_EXISTING=false

============================================================================
PROCESSING PIPELINE - Orchestration Settings
============================================================================
Global pipeline execution settings
PIPELINE_MAX_RETRIES=3
PIPELINE_TIMEOUT=300
PIPELINE_PARALLEL_PROCESSING=true
PIPELINE_MAX_CONCURRENT_JOBS=4
PIPELINE_LOG_LEVEL=DEBUG
PIPELINE_ENABLE_METRICS=true

Node execution order (don't change)
PIPELINE_NODE_ORDER=ingest,preprocess,chunk,embed,upsert

============================================================================
SESSION STORE - State Management Settings
============================================================================
Tracks pipeline execution state and caching
SESSION_STORE_BACKEND=sqlite
SESSION_DB_PATH=./data/sessions/sessions.db
SESSION_TIMEOUT_SECONDS=3600
SESSION_MAX_RETRIES=5

Optional: Redis (disabled for local development)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

Optional: MongoDB (disabled for local development)
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=rag_pipeline
MONGODB_COLLECTION=sessions

============================================================================
CACHING - Performance Optimization Settings
============================================================================
Cache preprocessed text, embeddings, and metadata
CACHE_ENABLED=true
CACHE_BACKEND=memory
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE_MB=1024
CACHE_PREPROCESS_ENABLED=true
CACHE_EMBEDDING_ENABLED=true
CACHE_CHUNK_ENABLED=true

Optional: Redis caching (disabled)
REDIS_CACHE_HOST=localhost
REDIS_CACHE_PORT=6379

============================================================================
API KEYS & TOKENS
============================================================================
HuggingFace Token (for downloading embeddings models)
HF_TOKEN=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

OpenAI API Key (Optional - only if using OpenAI embeddings)
OPENAI_API_KEY=

Not required for local setup
COHERE_API_KEY=
PINECONE_API_KEY=
QDRANT_API_KEY=

============================================================================
DATA PATHS - Input/Output Directories
============================================================================
Input paths
SOURCE_DOC_PATHS=./mock_data/raw_docs/
SOURCE_DOCUMENT_EXTENSIONS=.pdf,.txt,.docx,.json

Output paths
INGEST_OUTPUT_PATH=./mock_data/processed/
PREPROCESS_OUTPUT_PATH=./mock_data/preprocessed/
CHUNK_OUTPUT_PATH=./mock_data/chunks/
EMBEDDING_OUTPUT_PATH=./mock_data/embeddings/

Vector database paths
FAISS_INDEX_PATH=./mock_data/faiss_index
VECTOR_DB_DATA_PATH=./data/vectordb/

Cache paths
CACHE_DATA_PATH=./data/cache/
EMBEDDINGS_CACHE_FOLDER=./models/embeddings/
MODELS_CACHE_DIR=./models/

Logs and metrics
LOG_DIR=./logs/
METRICS_DIR=./metrics/

============================================================================
MODEL CONFIGURATION
============================================================================
Embedding Model (HuggingFace - Free)
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_MODEL_DEVICE=cpu
EMBEDDING_MODEL_BATCH_SIZE=32
EMBEDDING_MODEL_DIMENSION=384
EMBEDDING_MODEL_NORMALIZE_EMBEDDINGS=true
EMBEDDING_MODEL_POOL_METHOD=mean_pooling

Text Processing Model
TEXT_CLEANER=spacy
SPACY_MODEL=en_core_web_sm
SPACY_DISABLE_COMPONENTS=ner,parser
NLTK_DATA_PATH=./data/nltk_data/

============================================================================
PERFORMANCE & OPTIMIZATION
============================================================================
Parallel processing
PARALLEL_PROCESSING_ENABLED=true
MAX_WORKERS=4
THREAD_POOL_SIZE=8
PROCESS_POOL_SIZE=2

Memory management
MEMORY_LIMIT_MB=2048
BATCH_PROCESSING_ENABLED=true
STREAM_PROCESSING_ENABLED=false

Timeouts
GLOBAL_TIMEOUT_SECONDS=300
CHUNK_TIMEOUT_SECONDS=60
EMBED_TIMEOUT_SECONDS=120
UPSERT_TIMEOUT_SECONDS=60
INGEST_TIMEOUT_SECONDS=300

============================================================================
MONITORING & LOGGING
============================================================================
LOG_LEVEL=INFO
DEBUG_MODE=true
LOG_FORMAT=json
LOG_TO_FILE=true
LOG_TO_CONSOLE=true
LOG_FILE_PATH=./logs/pipeline.log

Metrics
METRICS_ENABLED=true
METRICS_INTERVAL_SECONDS=60
METRICS_EXPORT_FORMAT=prometheus

Tracing
TRACING_ENABLED=false
JAEGER_ENABLED=false
JAEGER_HOST=localhost
JAEGER_PORT=6831

============================================================================
QUALITY ASSURANCE
============================================================================
Validation
VALIDATE_INPUT_DOCUMENTS=true
VALIDATE_CHUNKS=true
VALIDATE_EMBEDDINGS=true
MIN_DOCUMENT_LENGTH=50
MIN_CHUNK_LENGTH=100
MAX_CHUNK_LENGTH=800

Deduplication
DEDUP_ENABLED=true
DEDUP_METHOD=hash
DEDUP_SIMILARITY_THRESHOLD=0.95

Error Handling
SKIP_FAILED_DOCUMENTS=true
MAX_RETRIES=3
RETRY_BACKOFF_FACTOR=2
CONTINUE_ON_ERROR=true

============================================================================
DEVELOPMENT MODE SETTINGS
============================================================================
Mock data generation
USE_MOCK_DATA=true
MOCK_DATA_SAMPLES=10
MOCK_DATA_PATH=./mock_data/

Testing
TESTING_MODE=false
TEST_DATA_PATH=./test_data/

Development features
ENABLE_API_PLAYGROUND=true
ENABLE_METRICS_DASHBOARD=true
ENABLE_DEBUG_LOGGING=true

============================================================================
SECURITY & COMPLIANCE
============================================================================
Data validation
VALIDATE_PDF_SIGNATURES=false
SCAN_FOR_MALWARE=false
VALIDATE_ENCODING=true

PII Detection (optional)
PII_DETECTION_ENABLED=false
PII_REDACTION_ENABLED=false

Rate limiting
RATE_LIMIT_ENABLED=false
RATE_LIMIT_REQUESTS_PER_MINUTE=100

============================================================================
END OF CONFIGURATION
============================================================================
QUICK START:
1. cp .env.dev .env
2. mkdir -p ./mock_data/raw_docs ./data/vectordb ./logs
3. Place PDF/TXT files in ./mock_data/raw_docs/
4. Run: python -m src.pipeline.orchestrator
PIPELINE FLOW:
raw_docs → ingest → preprocess → chunk → embed → upsert → faiss_index
All tools are FREE and LOCAL (no API keys needed)
============================================================================